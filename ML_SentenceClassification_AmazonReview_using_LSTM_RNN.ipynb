{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI0CCRYGbsLX"
      },
      "source": [
        "# Amazon Reviewsを用いてレビュー文の評価分類をLSTMとRNNで比較"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- データロード ---\n",
        "dataset = load_dataset(\"amazon_polarity\")\n",
        "train_texts = dataset[\"train\"][\"content\"][:50000]  # 軽量化\n",
        "train_labels = dataset[\"train\"][\"label\"][:50000]\n",
        "test_texts  = dataset[\"test\"][\"content\"][:10000]\n",
        "test_labels = dataset[\"test\"][\"label\"][:10000]\n",
        "\n",
        "# --- トークナイズ（数字も残す） ---\n",
        "def tokenize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9 ]\", \"\", text)  # 数字も残す\n",
        "    return text.split()\n",
        "\n",
        "train_tokens = [tokenize(t) for t in train_texts]\n",
        "test_tokens  = [tokenize(t) for t in test_texts]\n",
        "\n",
        "# --- 語彙作成（上位 50,000語） ---\n",
        "counter = Counter()\n",
        "for tokens in train_tokens:\n",
        "    counter.update(tokens)\n",
        "\n",
        "vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
        "for word, _ in counter.most_common(50000):\n",
        "    vocab[word] = len(vocab)\n",
        "\n",
        "def encode(tokens):\n",
        "    return torch.tensor([vocab.get(t, vocab[\"<unk>\"]) for t in tokens])\n",
        "\n",
        "train_encoded = [encode(t) for t in train_tokens]\n",
        "test_encoded  = [encode(t) for t in test_tokens]\n",
        "\n",
        "# --- DataLoader ---\n",
        "def collate_fn(batch):\n",
        "    texts, labels = zip(*batch)\n",
        "    texts = pad_sequence(texts, batch_first=True)\n",
        "    labels = torch.tensor(labels)\n",
        "    return texts, labels\n",
        "\n",
        "train_loader = DataLoader(list(zip(train_encoded, train_labels)), batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader  = DataLoader(list(zip(test_encoded, test_labels)), batch_size=64, collate_fn=collate_fn)\n",
        "\n",
        "# --- モデル定義（LSTM / RNN） ---\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, rnn_type=\"LSTM\"):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        if rnn_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 2)\n",
        "        self.rnn_type = rnn_type\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        if self.rnn_type == \"LSTM\":\n",
        "            _, (h, _) = self.rnn(x)\n",
        "        else:\n",
        "            _, h = self.rnn(x)\n",
        "        out = self.fc(h[-1])\n",
        "        return out\n",
        "\n",
        "# --- 学習関数 ---\n",
        "def train_model(model, train_loader, test_loader, epochs=5, lr=1e-3):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"{model.rnn_type} Epoch {epoch+1}, Loss: {total_loss:.3f}\")\n",
        "\n",
        "    # 評価\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x).argmax(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = correct / total\n",
        "    print(f\"{model.rnn_type} Test Accuracy: {acc:.4f}\")\n",
        "    return model, acc\n",
        "\n",
        "# --- ラベル & 単語復元 ---\n",
        "label_map = {0: \"negative\", 1: \"positive\"}\n",
        "idx_to_word = {idx: word for word, idx in vocab.items()}\n",
        "\n",
        "def decode_review(token_ids):\n",
        "    words = [idx_to_word.get(i, \"<unk>\") for i in token_ids if i != 0]\n",
        "    return \" \".join(words)\n",
        "\n",
        "def visualize_review(token_ids, y_true, y_pred, confidence, orig_text=\"\", title=\"Review\"):\n",
        "    print(f\"{title}:\")\n",
        "    print(\"Original:\", orig_text)  # 元の文章も表示\n",
        "    print(\"Tokenized:\", decode_review(token_ids))  # モデルに入ったトークン列\n",
        "    print(f\"Ground Truth : {label_map[y_true]}\")\n",
        "    print(f\"Prediction   : {label_map[y_pred]}\")\n",
        "    print(f\"Confidence   : {confidence:.3f}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# --- モデル作成 & 学習 ---\n",
        "lstm_model = SentimentRNN(len(vocab), rnn_type=\"LSTM\")\n",
        "rnn_model  = SentimentRNN(len(vocab), rnn_type=\"RNN\")\n",
        "\n",
        "lstm_model, lstm_acc = train_model(lstm_model, train_loader, test_loader)\n",
        "rnn_model, rnn_acc   = train_model(rnn_model, train_loader, test_loader)\n",
        "\n",
        "print(f\"\\nComparison -> LSTM Accuracy: {lstm_acc:.4f}, RNN Accuracy: {rnn_acc:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5kcEjtQBYDs",
        "outputId": "e2bbfca1-ab7e-4660-e338-c4db3cc09f7e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Epoch 1, Loss: 541.844\n",
            "LSTM Epoch 2, Loss: 528.238\n",
            "LSTM Epoch 3, Loss: 287.088\n",
            "LSTM Epoch 4, Loss: 183.813\n",
            "LSTM Epoch 5, Loss: 125.049\n",
            "LSTM Test Accuracy: 0.8731\n",
            "RNN Epoch 1, Loss: 542.618\n",
            "RNN Epoch 2, Loss: 541.661\n",
            "RNN Epoch 3, Loss: 543.998\n",
            "RNN Epoch 4, Loss: 546.622\n",
            "RNN Epoch 5, Loss: 544.783\n",
            "RNN Test Accuracy: 0.4875\n",
            "\n",
            "Comparison -> LSTM Accuracy: 0.8731, RNN Accuracy: 0.4875\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- サンプルレビュー比較 ---\n",
        "def compare_models_on_sample(idx):\n",
        "    x = test_encoded[idx].unsqueeze(0).to(device)\n",
        "    y_true = test_labels[idx]\n",
        "    orig_text = test_texts[idx]\n",
        "    with torch.no_grad():\n",
        "        lstm_pred_logits = lstm_model(x)\n",
        "        rnn_pred_logits  = rnn_model(x)\n",
        "        lstm_pred = torch.softmax(lstm_pred_logits, dim=1).argmax(1).item()\n",
        "        rnn_pred  = torch.softmax(rnn_pred_logits, dim=1).argmax(1).item()\n",
        "        lstm_conf = torch.softmax(lstm_pred_logits, dim=1)[0, lstm_pred].item()\n",
        "        rnn_conf  = torch.softmax(rnn_pred_logits, dim=1)[0, rnn_pred].item()\n",
        "    visualize_review(test_encoded[idx], y_true, lstm_pred, lstm_conf, orig_text, title=f\"LSTM/RNN Sample {idx+1}\")\n",
        "    print(f\"LSTM Prediction: {label_map[lstm_pred]} (conf: {lstm_conf:.3f})\")\n",
        "    print(f\"RNN  Prediction: {label_map[rnn_pred]} (conf: {rnn_conf:.3f})\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "for i in range(5):\n",
        "    compare_models_on_sample(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_DvPlhEBZF1",
        "outputId": "2d52f87a-a453-4c1a-b66e-4ba46cf71a48"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM/RNN Sample 1:\n",
            "Original: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : positive\n",
            "Prediction   : positive\n",
            "Confidence   : 0.954\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: positive (conf: 0.954)\n",
            "RNN  Prediction: positive (conf: 0.540)\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM/RNN Sample 2:\n",
            "Original: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : positive\n",
            "Prediction   : positive\n",
            "Confidence   : 0.984\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: positive (conf: 0.984)\n",
            "RNN  Prediction: negative (conf: 0.564)\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM/RNN Sample 3:\n",
            "Original: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : negative\n",
            "Prediction   : negative\n",
            "Confidence   : 0.979\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: negative (conf: 0.979)\n",
            "RNN  Prediction: negative (conf: 0.554)\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM/RNN Sample 4:\n",
            "Original: Check out Maha Energy's website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : positive\n",
            "Prediction   : positive\n",
            "Confidence   : 0.751\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: positive (conf: 0.751)\n",
            "RNN  Prediction: negative (conf: 0.554)\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM/RNN Sample 5:\n",
            "Original: Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don't want to replace them with DVD's. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : positive\n",
            "Prediction   : positive\n",
            "Confidence   : 0.842\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: positive (conf: 0.842)\n",
            "RNN  Prediction: negative (conf: 0.579)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 誤分類レビュー比較 ---\n",
        "def compare_misclassified(max_samples=5):\n",
        "    misclassified_count = 0\n",
        "    for i, (x_tokens, y_true) in enumerate(zip(test_encoded, test_labels)):\n",
        "        x = x_tokens.unsqueeze(0).to(device)\n",
        "        orig_text = test_texts[i]\n",
        "        with torch.no_grad():\n",
        "            lstm_pred = torch.softmax(lstm_model(x), dim=1).argmax(1).item()\n",
        "            rnn_pred  = torch.softmax(rnn_model(x), dim=1).argmax(1).item()\n",
        "            lstm_conf = torch.softmax(lstm_model(x), dim=1)[0, lstm_pred].item()\n",
        "            rnn_conf  = torch.softmax(rnn_model(x), dim=1)[0, rnn_pred].item()\n",
        "        if lstm_pred != y_true or rnn_pred != y_true:\n",
        "            misclassified_count += 1\n",
        "            visualize_review(x_tokens, y_true, lstm_pred, lstm_conf, orig_text, title=f\"Misclassified Review {misclassified_count}\")\n",
        "            print(f\"LSTM Prediction: {label_map[lstm_pred]} (conf: {lstm_conf:.3f})\")\n",
        "            print(f\"RNN  Prediction: {label_map[rnn_pred]} (conf: {rnn_conf:.3f})\")\n",
        "            print(\"-\"*80)\n",
        "            if misclassified_count >= max_samples:\n",
        "                break\n",
        "\n",
        "compare_misclassified(max_samples=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbO_gkepBb5E",
        "outputId": "ec6e2dd8-4894-4d02-a262-cee2af0e0990"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassified Review 1:\n",
            "Original: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : positive\n",
            "Prediction   : positive\n",
            "Confidence   : 0.984\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: positive (conf: 0.984)\n",
            "RNN  Prediction: negative (conf: 0.564)\n",
            "--------------------------------------------------------------------------------\n",
            "Misclassified Review 2:\n",
            "Original: Check out Maha Energy's website. Their Powerex MH-C204F charger works in 100 minutes for rapid charge, with option for slower charge (better for batteries). And they have 2200 mAh batteries.\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : positive\n",
            "Prediction   : positive\n",
            "Confidence   : 0.751\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: positive (conf: 0.751)\n",
            "RNN  Prediction: negative (conf: 0.554)\n",
            "--------------------------------------------------------------------------------\n",
            "Misclassified Review 3:\n",
            "Original: Reviewed quite a bit of the combo players and was hesitant due to unfavorable reviews and size of machines. I am weaning off my VHS collection, but don't want to replace them with DVD's. This unit is well built, easy to setup and resolution and special effects (no progressive scan for HDTV owners) suitable for many people looking for a versatile product.Cons- No universal remote.\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : positive\n",
            "Prediction   : positive\n",
            "Confidence   : 0.842\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: positive (conf: 0.842)\n",
            "RNN  Prediction: negative (conf: 0.579)\n",
            "--------------------------------------------------------------------------------\n",
            "Misclassified Review 4:\n",
            "Original: I also began having the incorrect disc problems that I've read about on here. The VCR still works, but hte DVD side is useless. I understand that DVD players sometimes just quit on you, but after not even one year? To me that's a sign on bad quality. I'm giving up JVC after this as well. I'm sticking to Sony or giving another brand a shot.\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : negative\n",
            "Prediction   : negative\n",
            "Confidence   : 0.889\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: negative (conf: 0.889)\n",
            "RNN  Prediction: positive (conf: 0.591)\n",
            "--------------------------------------------------------------------------------\n",
            "Misclassified Review 5:\n",
            "Original: Exotic tales of the Orient from the 1930's. \"Dr Shen Fu\", a Weird Tales magazine reprint, is about the elixir of life that grants immortality at a price. If you're tired of modern authors who all sound alike, this is the antidote for you. Owen's palette is loaded with splashes of Chinese and Japanese colours. Marvelous.\n",
            "Tokenized: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "Ground Truth : positive\n",
            "Prediction   : positive\n",
            "Confidence   : 0.940\n",
            "--------------------------------------------------------------------------------\n",
            "LSTM Prediction: positive (conf: 0.940)\n",
            "RNN  Prediction: negative (conf: 0.555)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- 詳細比較表作成 ---\n",
        "def compute_detailed_metrics(model, test_encoded, test_labels):\n",
        "    \"\"\"モデルごとの詳細評価指標を計算\"\"\"\n",
        "    correct, total = 0, 0\n",
        "    tp, tn, fp, fn = 0, 0, 0, 0  # 正例／負例ごとの分類\n",
        "    for x_tokens, y_true in zip(test_encoded, test_labels):\n",
        "        x = x_tokens.unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = torch.softmax(model(x), dim=1).argmax(1).item()\n",
        "        total += 1\n",
        "        if pred == y_true:\n",
        "            correct += 1\n",
        "            if y_true == 1:\n",
        "                tp += 1\n",
        "            else:\n",
        "                tn += 1\n",
        "        else:\n",
        "            if y_true == 1:\n",
        "                fn += 1\n",
        "            else:\n",
        "                fp += 1\n",
        "    accuracy = correct / total\n",
        "    pos_acc = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    neg_acc = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    misclassified_rate = 1 - accuracy\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Misclassified Rate\": misclassified_rate,\n",
        "        \"Positive Accuracy\": pos_acc,\n",
        "        \"Negative Accuracy\": neg_acc\n",
        "    }\n",
        "\n",
        "# 各モデルの詳細評価\n",
        "lstm_metrics = compute_detailed_metrics(lstm_model, test_encoded, test_labels)\n",
        "rnn_metrics  = compute_detailed_metrics(rnn_model, test_encoded, test_labels)\n",
        "\n",
        "# DataFrame にまとめる\n",
        "df_metrics = pd.DataFrame([lstm_metrics, rnn_metrics], index=[\"LSTM\", \"RNN\"])\n",
        "print(\"\\nDetailed Comparison Table:\")\n",
        "print(df_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POO5_jiBC9e9",
        "outputId": "cb4df51a-4493-4796-bf79-1033dd4d92d4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed Comparison Table:\n",
            "      Accuracy  Misclassified Rate  Positive Accuracy  Negative Accuracy\n",
            "LSTM    0.8655              0.1345           0.859707           0.871590\n",
            "RNN     0.5001              0.4999           0.505171           0.494769\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}